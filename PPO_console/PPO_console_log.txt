training environment name : RichDog
--------------------------------------------------------------------------------------------
max training timesteps :  10000000
max timesteps per episode :  361
model saving frequency : 100000 timesteps
log frequency : 2000 timesteps
printing average reward over episodes in last : 3600 timesteps
--------------------------------------------------------------------------------------------
state space dimension :  Dict('img': Box(0.0, 1.0, (8, 60, 60), float32), 'num': Box(-inf, inf, (14,), float32))
action space dimension :  Box(-1.0, 1.0, (1,), float32)
--------------------------------------------------------------------------------------------
Initializing a continuous action space policy
--------------------------------------------------------------------------------------------
starting std of action distribution :  0.6
decay rate of std of action distribution :  0.01282051282051282
minimum std of action distribution :  0.1
decay frequency of std of action distribution : 250000 timesteps
--------------------------------------------------------------------------------------------
PPO update frequency : 1440 timesteps
PPO K epochs :  10
PPO epsilon clip :  0.2
discount factor (gamma) :  0.99
GAE discount factor (lamda) :  0.95
mini batch size :  128
--------------------------------------------------------------------------------------------
optimizer learning rate actor :  0.0003
optimizer learning rate critic :  0.001
============================================================================================
Started training at (GMT) : 2025-06-02 16:54:04
============================================================================================
Episode : 33 		 Timestep : 3600 		 Average Reward : -22.2
