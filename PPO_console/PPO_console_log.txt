training environment name : RichDog
--------------------------------------------------------------------------------------------
max training timesteps :  10000000
max timesteps per episode :  361
model saving frequency : 100000 timesteps
log frequency : 2000 timesteps
printing average reward over episodes in last : 3600 timesteps
--------------------------------------------------------------------------------------------
state space dimension :  Dict('img': Box(-1.0, 1.0, (3, 128, 128), float32), 'num': Box(-inf, inf, (15,), float32))
action space dimension :  Box(-1.0, 1.0, (1,), float32)
--------------------------------------------------------------------------------------------
Initializing a continuous action space policy
--------------------------------------------------------------------------------------------
starting std of action distribution :  0.6
decay rate of std of action distribution :  0.007692307692307692
minimum std of action distribution :  0.3
decay frequency of std of action distribution : 250000 timesteps
--------------------------------------------------------------------------------------------
PPO update frequency : 1440 timesteps
PPO K epochs :  10
PPO epsilon clip :  0.2
discount factor (gamma) :  0.99
GAE discount factor (lamda) :  0.95
mini batch size :  128
--------------------------------------------------------------------------------------------
optimizer learning rate actor :  1e-05
optimizer learning rate critic :  0.0001
============================================================================================
Started training at (GMT) : 2025-07-05 11:25:31
============================================================================================
Episode : 10 		 Timestep : 3600 		 Average Reward : -29646641589897.49
